{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'theano'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4a9216532666>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'theano'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_bias(n = 1):\n",
    "    return(theano.shared(np.zeros(n), theano.config.floatX))\n",
    "\n",
    "def init_weights(n_in=1, n_out=1, logistic=True):\n",
    "    W_values = np.asarray(\n",
    "        np.random.uniform(\n",
    "        low=-np.sqrt(6. / (n_in + n_out)),\n",
    "        high=np.sqrt(6. / (n_in + n_out)),\n",
    "        size=(n_in, n_out)),\n",
    "        dtype=theano.config.floatX\n",
    "        )\n",
    "    if logistic == True:\n",
    "        W_values *= 4\n",
    "    return (theano.shared(value=W_values, name='W', borrow=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scale data\n",
    "def scale(X, X_min, X_max):\n",
    "    return (X - X_min)/(X_max-np.min(X, axis=0))\n",
    "\n",
    "# update parameters\n",
    "def sgd(cost, params, lr=0.01):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    for p, g in zip(params, grads):\n",
    "        updates.append([p, p - g * lr])\n",
    "    return updates\n",
    "\n",
    "def shuffle_data (samples, labels):\n",
    "    idx = np.arange(samples.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    #print  (samples.shape, labels.shape)\n",
    "    samples, labels = samples[idx], labels[idx]\n",
    "    return samples, labels\n",
    "\n",
    "def read_data(filename):\n",
    "    input_data = np.loadtxt(filename,delimiter=' ')\n",
    "    X, _Y = input_data[:,:36], input_data[:,-1].astype(int)\n",
    "    X = scale(X, np.min(X, axis=0), np.max(X, axis=0))\n",
    "    \n",
    "    _Y[_Y == 7] = 6\n",
    "    Y = np.zeros((_Y.shape[0], 6))\n",
    "    Y[np.arange(_Y.shape[0]), _Y-1] = 1\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train_network(trainX, trainY, testX, testY, decay, learning_rate, epochs, batch_size, num_neurons):    \n",
    "    # theano expressions\n",
    "    X = T.matrix() #features\n",
    "    Y = T.matrix() #output\n",
    "\n",
    "    w1, b1 = init_weights(36, num_neurons), init_bias(num_neurons) #weights and biases from input to hidden layer\n",
    "    w2, b2 = init_weights(num_neurons, 6, logistic=False), init_bias(6) #weights and biases from hidden to output layer\n",
    "\n",
    "    h1 = T.nnet.sigmoid(T.dot(X, w1) + b1)\n",
    "    py = T.nnet.softmax(T.dot(h1, w2) + b2)\n",
    "\n",
    "    y_x = T.argmax(py, axis=1)\n",
    "\n",
    "    cost = T.mean(T.nnet.categorical_crossentropy(py, Y)) + decay*(T.sum(T.sqr(w1)+T.sum(T.sqr(w2))))\n",
    "    params = [w1, b1, w2, b2]\n",
    "    updates = sgd(cost, params, learning_rate)\n",
    "\n",
    "    # compile\n",
    "    train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n",
    "    predict = theano.function(inputs=[X], outputs=y_x, allow_input_downcast=True)\n",
    "    \n",
    "    # train and test\n",
    "    n = len(trainX)\n",
    "    test_accuracy = []\n",
    "    train_cost = []\n",
    "    batch_time_used = []\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "\n",
    "        trainX, trainY = shuffle_data(trainX, trainY)\n",
    "        cost = 0.0\n",
    "        for start, end in zip(range(0, n, batch_size), range(batch_size, n, batch_size)):\n",
    "            start_time = time.time()\n",
    "            cost += train(trainX[start:end], trainY[start:end])\n",
    "            batch_time_used.append(time.time()*1000-start_time*1000)\n",
    "        \n",
    "        \n",
    "        train_cost = np.append(train_cost, cost/(n // batch_size))\n",
    "\n",
    "        test_accuracy = np.append(test_accuracy, np.mean(np.argmax(testY, axis=1) == predict(testX)))\n",
    "\n",
    "    print('%.1f accuracy at %d iterations'%(np.max(test_accuracy)*100, np.argmax(test_accuracy)+1))\n",
    "\n",
    "    return train_cost, test_accuracy, np.mean(batch_time_used), np.sum(batch_time_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train_4layers(trainX, trainY, testX, testY, decay, learning_rate, epochs, batch_size, num_neurons):    \n",
    "    # theano expressions\n",
    "    X = T.matrix() #features\n",
    "    Y = T.matrix() #output\n",
    "\n",
    "    w1, b1 = init_weights(36, num_neurons), init_bias(num_neurons) #weights and biases from input to hidden layer\n",
    "    w2, b2 = init_weights(num_neurons, num_neurons), init_bias(num_neurons)\n",
    "    w3, b3 = init_weights(num_neurons, 6, logistic=False), init_bias(6) #weights and biases from hidden to output layer\n",
    "\n",
    "    h1 = T.nnet.sigmoid(T.dot(X, w1) + b1)\n",
    "    h2 = T.nnet.sigmoid(T.dot(h1, w2) + b2)\n",
    "    py = T.nnet.softmax(T.dot(h2, w3) + b3)\n",
    "\n",
    "    y_x = T.argmax(py, axis=1)\n",
    "\n",
    "    cost = T.mean(T.nnet.categorical_crossentropy(py, Y)) + decay*(T.sum(T.sqr(w1)+T.sum(T.sqr(w2)+T.sum(T.sqr(w3)))))\n",
    "    params = [w1, b1, w2, b2, w3, b3]\n",
    "    updates = sgd(cost, params, learning_rate)\n",
    "\n",
    "    # compile\n",
    "    train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n",
    "    predict = theano.function(inputs=[X], outputs=y_x, allow_input_downcast=True)\n",
    "    \n",
    "    # train and test\n",
    "    n = len(trainX)\n",
    "    test_accuracy = []\n",
    "    train_cost = []\n",
    "    batch_time_used = []\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "\n",
    "        trainX, trainY = shuffle_data(trainX, trainY)\n",
    "        cost = 0.0\n",
    "        for start, end in zip(range(0, n, batch_size), range(batch_size, n, batch_size)):\n",
    "            start_time = time.time()\n",
    "            cost += train(trainX[start:end], trainY[start:end])\n",
    "            batch_time_used.append(time.time()*1000-start_time*1000)\n",
    "        \n",
    "        \n",
    "        train_cost = np.append(train_cost, cost/(n // batch_size))\n",
    "\n",
    "        test_accuracy = np.append(test_accuracy, np.mean(np.argmax(testY, axis=1) == predict(testX)))\n",
    "\n",
    "    print('%.1f accuracy at %d iterations'%(np.max(test_accuracy)*100, np.argmax(test_accuracy)+1))\n",
    "\n",
    "    return train_cost, test_accuracy, np.mean(batch_time_used), np.sum(batch_time_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Point out the maximum and minimum point\n",
    "\n",
    "def annot_max(x,y, ax=None):\n",
    "    xmax = x[np.argmax(y)]\n",
    "    ymax = y.max()\n",
    "    text= \"MAX Point x={:.3f}, y={:.3f}\".format(xmax, ymax)\n",
    "    if not ax:\n",
    "        ax=plt.gca()\n",
    "    bbox_props = dict(boxstyle=\"square,pad=0.3\", fc=\"w\", ec=\"k\", lw=0.72)\n",
    "    arrowprops=dict(arrowstyle=\"->\",connectionstyle=\"angle,angleA=0,angleB=60\")\n",
    "    kw = dict(xycoords='data',textcoords=\"axes fraction\",\n",
    "              arrowprops=arrowprops, bbox=bbox_props, ha=\"right\", va=\"top\")\n",
    "    ax.annotate(text, xy=(xmax, ymax), xytext=(0.94,0.1), **kw)\n",
    "\n",
    "def annot_min(x,y, ax=None):\n",
    "    xmin = x[np.argmin(y)]\n",
    "    ymin = y.min()\n",
    "    text= \"MIN Point x={:.3f}, y={:.3f}\".format(xmin, ymin)\n",
    "    if not ax:\n",
    "        ax=plt.gca()\n",
    "    bbox_props = dict(boxstyle=\"square,pad=0.3\", fc=\"w\", ec=\"k\", lw=0.72)\n",
    "    arrowprops=dict(arrowstyle=\"->\",connectionstyle=\"angle,angleA=0,angleB=120\")\n",
    "    kw = dict(xycoords='data',textcoords=\"axes fraction\",\n",
    "              arrowprops=arrowprops, bbox=bbox_props, ha=\"right\", va=\"bottom\")\n",
    "    ax.annotate(text, xy=(xmin, ymin), xytext=(0.94,0.9), **kw)\n",
    "\n",
    "# This is for plot train errors and test accuracies against epochs\n",
    "def plot1(filename, train_cost, test_accuracy, epochs=1000): \n",
    "\n",
    "    #Plots\n",
    "    plt.figure()\n",
    "    plt.plot(range(epochs), train_cost)\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel('cross-entropy')\n",
    "    plt.title('training cost')\n",
    "    annot_min(range(epochs), train_cost)\n",
    "    plt.savefig(filename + '_cost.png')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(range(epochs), test_accuracy)\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('test accuracy')\n",
    "    annot_max(range(epochs), test_accuracy)\n",
    "    plt.savefig(filename + '_accuracy.png')\n",
    "\n",
    "#This is for plot time against parameters\n",
    "def plot2(filename, parameters, parameter_name, updatetimes, totaltimes):\n",
    "    # update time\n",
    "    plt.figure()\n",
    "    plt.plot(parameters, updatetimes)\n",
    "    plt.xlabel(parameter_name)\n",
    "    plt.ylabel('time in ms')\n",
    "    plt.title('time for a weight update')\n",
    "    plt.savefig(filename + '_update_time.png')\n",
    "    \n",
    "    # total time\n",
    "    plt.figure()\n",
    "    plt.plot(parameters, totaltimes)\n",
    "    plt.xlabel(parameter_name)\n",
    "    plt.ylabel('time in s')\n",
    "    plt.title('total time for training')\n",
    "    plt.savefig(filename + '_total_time.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4435, 36) (4435, 6)\n",
      "(2000, 36) (2000, 6)\n"
     ]
    }
   ],
   "source": [
    "# Prepare Data\n",
    "trainX, trainY = read_data('sat_train.txt')\n",
    "testX, testY = read_data('sat_test.txt')\n",
    "    \n",
    "print(trainX.shape, trainY.shape)\n",
    "print(testX.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train_network() missing 1 required positional argument: 'num_neurons'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-3c9ff760cb42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplot1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./graph_theano/1/question1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_cost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: train_network() missing 1 required positional argument: 'num_neurons'"
     ]
    }
   ],
   "source": [
    "# Question 1\n",
    "\n",
    "decay = 1e-6\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "num_neurons = 10\n",
    "batch_size = 32\n",
    "\n",
    "train_cost, test_accuracy, update_time, total_time = train_network(trainX, trainY, testX, testY, decay, learning_rate, epochs, batch_size, num_neurons)\n",
    "plot1(filename='./graph_theano/1/question1', train_cost=train_cost, test_accuracy=test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running batch size: 4\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "86.9 accuracy at 1000 iterations\n",
      "Taken average 0.034478969092 ms to update weight once\n",
      "Taken 38.2026977539 s total time\n",
      "Running batch size: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/syy/anaconda3/envs/theano/lib/python3.6/site-packages/matplotlib/pyplot.py:524: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "85.4 accuracy at 971 iterations\n",
      "Taken average 0.0380449729947 ms to update weight once\n",
      "Taken 21.0769150391 s total time\n",
      "Running batch size: 16\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "83.8 accuracy at 994 iterations\n",
      "Taken average 0.0447692994486 ms to update weight once\n",
      "Taken 12.4010959473 s total time\n",
      "Running batch size: 32\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "82.0 accuracy at 944 iterations\n",
      "Taken average 0.0550065387228 ms to update weight once\n",
      "Taken 7.59090234375 s total time\n",
      "Running batch size: 64\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "81.0 accuracy at 996 iterations\n",
      "Taken average 0.0756721792912 ms to update weight once\n",
      "Taken 5.22138037109 s total time\n"
     ]
    }
   ],
   "source": [
    "# Question 2\n",
    "\n",
    "decay = 1e-6\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "num_neurons = 10\n",
    "batches = [4, 8, 16, 32, 64]\n",
    "\n",
    "updateTimes = []\n",
    "totalTimes = []\n",
    "\n",
    "for batch_size in batches:\n",
    "    print(\"Running batch size: \"+str(batch_size))\n",
    "    train_cost, test_accuracy, update_time, total_time = train_network(trainX, trainY, testX, testY, decay, learning_rate, epochs, batch_size, num_neurons)\n",
    "    updateTimes.append(update_time)\n",
    "    totalTimes.append(total_time/1000)\n",
    "    \n",
    "    print(\"Taken average \" + str(update_time) + \" ms to update weight once\")\n",
    "    print(\"Taken \" + str(total_time/1000) + \" s total time\")\n",
    "    plot1(filename='./graph_theano/2/batch_'+str(batch_size), train_cost=train_cost, test_accuracy=test_accuracy)\n",
    "\n",
    "plot2('./graph_theano/2/batch', batches, 'batch size', updateTimes, totalTimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running num of neurons: 5\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "85.9 accuracy at 904 iterations\n",
      "Taken average 0.0338267976506 ms to update weight once\n",
      "Taken 37.4800917969 s total time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/syy/anaconda3/envs/theano/lib/python3.6/site-packages/matplotlib/pyplot.py:524: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running num of neurons: 10\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "86.9 accuracy at 988 iterations\n",
      "Taken average 0.0342567383253 ms to update weight once\n",
      "Taken 37.9564660645 s total time\n",
      "Running num of neurons: 15\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "87.2 accuracy at 969 iterations\n",
      "Taken average 0.0359260890699 ms to update weight once\n",
      "Taken 39.8061066895 s total time\n",
      "Running num of neurons: 20\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "86.9 accuracy at 925 iterations\n",
      "Taken average 0.0361763468718 ms to update weight once\n",
      "Taken 40.083392334 s total time\n",
      "Running num of neurons: 25\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "86.9 accuracy at 950 iterations\n",
      "Taken average 0.0375708181884 ms to update weight once\n",
      "Taken 41.6284665527 s total time\n"
     ]
    }
   ],
   "source": [
    "# Question 3\n",
    "\n",
    "decay = 1e-6\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "nums_neurons = [5, 10, 15, 20, 25]\n",
    "batch_size = 4\n",
    "\n",
    "updateTimes = []\n",
    "totalTimes = []\n",
    "\n",
    "for num_neurons in nums_neurons:\n",
    "    print(\"Running num of neurons: \"+str(num_neurons))\n",
    "    train_cost, test_accuracy, update_time, total_time = train_network(trainX, trainY, testX, testY, decay, learning_rate, epochs, batch_size, num_neurons)\n",
    "    updateTimes.append(update_time)\n",
    "    totalTimes.append(total_time/1000)\n",
    "    \n",
    "    print(\"Taken average \" + str(update_time) + \" ms to update weight once\")\n",
    "    print(\"Taken \" + str(total_time/1000) + \" s total time\")\n",
    "    plot1(filename='./graph_theano/3/neurons_'+str(num_neurons), train_cost=train_cost, test_accuracy=test_accuracy)\n",
    "\n",
    "plot2('./graph_theano/3/neurons', batches, 'number of neurons', updateTimes, totalTimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running decay: 0\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "88.9 accuracy at 938 iterations\n",
      "Taken average 0.0316321318589 ms to update weight once\n",
      "Taken 35.0484020996 s total time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/syy/anaconda3/envs/theano/lib/python3.6/site-packages/matplotlib/pyplot.py:524: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running decay: 0.001\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "58.2 accuracy at 213 iterations\n",
      "Taken average 0.035156127489 ms to update weight once\n",
      "Taken 38.9529892578 s total time\n",
      "Running decay: 1e-06\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "86.8 accuracy at 948 iterations\n",
      "Taken average 0.0353317602275 ms to update weight once\n",
      "Taken 39.147590332 s total time\n",
      "Running decay: 1e-09\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "88.9 accuracy at 1000 iterations\n",
      "Taken average 0.03432731678 ms to update weight once\n",
      "Taken 38.0346669922 s total time\n",
      "Running decay: 1e-12\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "89.5 accuracy at 937 iterations\n",
      "Taken average 0.0344572641531 ms to update weight once\n",
      "Taken 38.1786486816 s total time\n"
     ]
    }
   ],
   "source": [
    "# Question 4\n",
    "\n",
    "decays = [0, 1e-3, 1e-6, 1e-9, 1e-12]\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "num_neurons = 15\n",
    "batch_size = 4\n",
    "\n",
    "updateTimes = []\n",
    "totalTimes = []\n",
    "\n",
    "for decay in decays:\n",
    "    print(\"Running decay: \"+str(decay))\n",
    "    train_cost, test_accuracy, update_time, total_time = train_network(trainX, trainY, testX, testY, decay, learning_rate, epochs, batch_size, num_neurons)\n",
    "    updateTimes.append(update_time)\n",
    "    totalTimes.append(total_time/1000)\n",
    "    \n",
    "    print(\"Taken average \" + str(update_time) + \" ms to update weight once\")\n",
    "    print(\"Taken \" + str(total_time/1000) + \" s total time\")\n",
    "    plot1(filename='./graph_theano/4/decay_'+str(decay), train_cost=train_cost, test_accuracy=test_accuracy)\n",
    "\n",
    "plot2('./graph_theano/4/decay_', batches, 'decay', updateTimes, totalTimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 4 layers...\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "82.3 accuracy at 997 iterations\n",
      "Taken average 0.0731125842108 ms to update weight once\n",
      "Taken 10.0895366211 s total time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/syy/anaconda3/envs/theano/lib/python3.6/site-packages/matplotlib/pyplot.py:524: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Question 5\n",
    "\n",
    "decays = 1e-6\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "num_neurons = 10\n",
    "batch_size = 32\n",
    "\n",
    "updateTimes = []\n",
    "totalTimes = []\n",
    "\n",
    "print(\"Running 4 layers...\")\n",
    "train_cost, test_accuracy, update_time, total_time = train_4layers(trainX, trainY, testX, testY, decay, learning_rate, epochs, batch_size, num_neurons)\n",
    "updateTimes.append(update_time)\n",
    "totalTimes.append(total_time/1000)\n",
    "\n",
    "print(\"Taken average \" + str(update_time) + \" ms to update weight once\")\n",
    "print(\"Taken \" + str(total_time/1000) + \" s total time\")\n",
    "plot1(filename='./graph_theano/5/4layers', train_cost=train_cost, test_accuracy=test_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
