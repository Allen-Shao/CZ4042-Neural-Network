{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_bias(n = 1):\n",
    "    return(theano.shared(np.zeros(n), theano.config.floatX))\n",
    "\n",
    "def init_weights(n_in=1, n_out=1, logistic=True):\n",
    "    W_values = np.asarray(\n",
    "        np.random.uniform(\n",
    "        low=-np.sqrt(6. / (n_in + n_out)),\n",
    "        high=np.sqrt(6. / (n_in + n_out)),\n",
    "        size=(n_in, n_out)),\n",
    "        dtype=theano.config.floatX\n",
    "        )\n",
    "    if logistic == True:\n",
    "        W_values *= 4\n",
    "    return (theano.shared(value=W_values, name='W', borrow=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scale data\n",
    "X_min = None\n",
    "X_max = None\n",
    "def scale(X):\n",
    "    return (X - X_min)/(X_max-np.min(X, axis=0))\n",
    "# def scale(X, X_min, X_max):\n",
    "#     return (X - X_min)/(X_max-np.min(X, axis=0))\n",
    "\n",
    "# update parameters\n",
    "def sgd(cost, params, lr=0.01):\n",
    "    grads = T.grad(cost=cost, wrt=params) # compute the gradient of cost \n",
    "    updates = []\n",
    "    for p, g in zip(params, grads):\n",
    "        updates.append([p, p - g * lr])\n",
    "    return updates\n",
    "\n",
    "def shuffle_data (samples, labels):\n",
    "    idx = np.arange(samples.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    #print  (samples.shape, labels.shape)\n",
    "    samples, labels = samples[idx], labels[idx]\n",
    "    return samples, labels\n",
    "\n",
    "def read_data(filename):\n",
    "    \"\"\"\n",
    "    Reading the file and return scaled features and labels\n",
    "    \"\"\"\n",
    "    input_data = np.loadtxt(filename,delimiter=' ')\n",
    "    X, _Y = input_data[:,:36], input_data[:,-1].astype(int)\n",
    "#     X = scale(X, np.min(X, axis=0), np.max(X, axis=0))\n",
    "\n",
    "    \n",
    "    _Y[_Y == 7] = 6\n",
    "    Y = np.zeros((_Y.shape[0], 6))\n",
    "    Y[np.arange(_Y.shape[0]), _Y-1] = 1\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_network(trainX, trainY, testX, testY, decay, learning_rate, epochs, batch_size, num_neurons):    \n",
    "    # theano expressions\n",
    "    X = T.matrix() #features\n",
    "    Y = T.matrix() #output\n",
    "\n",
    "    w1, b1 = init_weights(36, num_neurons), init_bias(num_neurons) #weights and biases from input to hidden layer\n",
    "    w2, b2 = init_weights(num_neurons, 6, logistic=False), init_bias(6) #weights and biases from hidden to output layer\n",
    "\n",
    "#     activation\n",
    "    h1 = T.nnet.sigmoid(T.dot(X, w1) + b1)\n",
    "    py = T.nnet.softmax(T.dot(h1, w2) + b2)\n",
    "\n",
    "    y_x = T.argmax(py, axis=1)\n",
    "\n",
    "    cost = T.mean(T.nnet.categorical_crossentropy(py, Y)) + decay*(T.sum(T.sqr(w1)+T.sum(T.sqr(w2))))\n",
    "    params = [w1, b1, w2, b2]\n",
    "    updates = sgd(cost, params, learning_rate)\n",
    "\n",
    "    # compile\n",
    "    train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n",
    "    predict = theano.function(inputs=[X], outputs=y_x, allow_input_downcast=True)\n",
    "    \n",
    "    # train and test\n",
    "    n = len(trainX)\n",
    "    test_accuracy = []\n",
    "    train_cost = []\n",
    "    batch_time_used = []\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "\n",
    "        trainX, trainY = shuffle_data(trainX, trainY)\n",
    "        cost = 0.0\n",
    "        for start, end in zip(range(0, n, batch_size), range(batch_size, n, batch_size)):\n",
    "            start_time = time.time()\n",
    "            cost += train(trainX[start:end], trainY[start:end])\n",
    "            batch_time_used.append(time.time()*1000-start_time*1000)\n",
    "        \n",
    "        \n",
    "        train_cost = np.append(train_cost, cost/(n // batch_size))\n",
    "\n",
    "        test_accuracy = np.append(test_accuracy, np.mean(np.argmax(testY, axis=1) == predict(testX)))\n",
    "\n",
    "    print('%.1f accuracy at %d iterations'%(np.max(test_accuracy)*100, np.argmax(test_accuracy)+1))\n",
    "\n",
    "    return train_cost, test_accuracy, np.mean(batch_time_used), np.sum(batch_time_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_4layers(trainX, trainY, testX, testY, decay, learning_rate, epochs, batch_size, num_neurons):    \n",
    "    # theano expressions\n",
    "    X = T.matrix() #features\n",
    "    Y = T.matrix() #output\n",
    "\n",
    "    w1, b1 = init_weights(36, num_neurons), init_bias(num_neurons) #weights and biases from input to hidden layer\n",
    "    w2, b2 = init_weights(num_neurons, num_neurons), init_bias(num_neurons)\n",
    "    w3, b3 = init_weights(num_neurons, 6, logistic=False), init_bias(6) #weights and biases from hidden to output layer\n",
    "\n",
    "    # activation\n",
    "    h1 = T.nnet.sigmoid(T.dot(X, w1) + b1) \n",
    "    h2 = T.nnet.sigmoid(T.dot(h1, w2) + b2)\n",
    "    py = T.nnet.softmax(T.dot(h2, w3) + b3)\n",
    "\n",
    "    y_x = T.argmax(py, axis=1)\n",
    "\n",
    "    cost = T.mean(T.nnet.categorical_crossentropy(py, Y)) + decay*(T.sum(T.sqr(w1)+T.sum(T.sqr(w2)))) + decay*(T.sum(T.sqr(w2)+T.sum(T.sqr(w3))))\n",
    "    params = [w1, b1, w2, b2, w3, b3]\n",
    "    updates = sgd(cost, params, learning_rate)\n",
    "\n",
    "    # compile\n",
    "    train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n",
    "    predict = theano.function(inputs=[X], outputs=y_x, allow_input_downcast=True)\n",
    "    \n",
    "    # train and test\n",
    "    n = len(trainX)\n",
    "    test_accuracy = []\n",
    "    train_cost = []\n",
    "    batch_time_used = []\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "\n",
    "        trainX, trainY = shuffle_data(trainX, trainY)\n",
    "        cost = 0.0\n",
    "        for start, end in zip(range(0, n, batch_size), range(batch_size, n, batch_size)):\n",
    "            start_time = time.time()\n",
    "            cost += train(trainX[start:end], trainY[start:end])\n",
    "            batch_time_used.append(time.time()*1000-start_time*1000)\n",
    "        \n",
    "        \n",
    "        train_cost = np.append(train_cost, cost/(n // batch_size))\n",
    "\n",
    "        test_accuracy = np.append(test_accuracy, np.mean(np.argmax(testY, axis=1) == predict(testX)))\n",
    "\n",
    "    print('%.1f accuracy at %d iterations'%(np.max(test_accuracy)*100, np.argmax(test_accuracy)+1))\n",
    "\n",
    "    return train_cost, test_accuracy, np.mean(batch_time_used), np.sum(batch_time_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Point out the maximum and minimum point\n",
    "\n",
    "def annot_max(x,y, ax=None):\n",
    "    xmax = x[np.argmax(y)]\n",
    "    ymax = y.max()\n",
    "    text= \"MAX Point x={:.3f}, y={:.3f}\".format(xmax, ymax)\n",
    "    if not ax:\n",
    "        ax=plt.gca()\n",
    "    bbox_props = dict(boxstyle=\"square,pad=0.3\", fc=\"w\", ec=\"k\", lw=0.72)\n",
    "    arrowprops=dict(arrowstyle=\"->\",connectionstyle=\"angle,angleA=0,angleB=60\")\n",
    "    kw = dict(xycoords='data',textcoords=\"axes fraction\",\n",
    "              arrowprops=arrowprops, bbox=bbox_props, ha=\"right\", va=\"top\")\n",
    "    ax.annotate(text, xy=(xmax, ymax), xytext=(0.94,0.1), **kw)\n",
    "\n",
    "def annot_min(x,y, ax=None):\n",
    "    xmin = x[np.argmin(y)]\n",
    "    ymin = y.min()\n",
    "    text= \"MIN Point x={:.3f}, y={:.3f}\".format(xmin, ymin)\n",
    "    if not ax:\n",
    "        ax=plt.gca()\n",
    "    bbox_props = dict(boxstyle=\"square,pad=0.3\", fc=\"w\", ec=\"k\", lw=0.72)\n",
    "    arrowprops=dict(arrowstyle=\"->\",connectionstyle=\"angle,angleA=0,angleB=120\")\n",
    "    kw = dict(xycoords='data',textcoords=\"axes fraction\",\n",
    "              arrowprops=arrowprops, bbox=bbox_props, ha=\"right\", va=\"bottom\")\n",
    "    ax.annotate(text, xy=(xmin, ymin), xytext=(0.94,0.9), **kw)\n",
    "\n",
    "# This is for plot train errors and test accuracies against epochs\n",
    "def plot1(filename, train_cost, test_accuracy, epochs=1000): \n",
    "\n",
    "    #Plots\n",
    "    plt.figure()\n",
    "    plt.plot(range(epochs), train_cost)\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel('cross-entropy')\n",
    "    plt.title('training cost')\n",
    "    annot_min(range(epochs), train_cost)\n",
    "    plt.savefig(filename + '_cost.png')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(range(epochs), test_accuracy)\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('test accuracy')\n",
    "    annot_max(range(epochs), test_accuracy)\n",
    "    plt.savefig(filename + '_accuracy.png')\n",
    "    \n",
    "\n",
    "#This is for plot time against parameters\n",
    "def plot2(filename, parameters, parameter_name, updatetimes, totaltimes):\n",
    "    # update time\n",
    "    plt.figure()\n",
    "    plt.plot(parameters, updatetimes)\n",
    "    plt.xlabel(parameter_name)\n",
    "    plt.ylabel('time in ms')\n",
    "    plt.title('time for a weight update')\n",
    "    plt.savefig(filename + '_update_time.png')\n",
    "    \n",
    "    # total time\n",
    "    plt.figure()\n",
    "    plt.plot(parameters, totaltimes)\n",
    "    plt.xlabel(parameter_name)\n",
    "    plt.ylabel('time in s')\n",
    "    plt.title('total time for training')\n",
    "    plt.savefig(filename + '_total_time.png')\n",
    "    \n",
    "def histogram(x, y, para_name, file_name, ylabel, title):\n",
    "    # plot the histogram\n",
    "    fig, ax = plt.subplots(figsize=(10,6))\n",
    "    rect = ax.bar([0,1,2,3,4],y,align='center') # A bar chart\n",
    "   \n",
    "    def autolabel(rects):\n",
    "        \"\"\"\n",
    "        Attach a text label above each bar displaying its height\n",
    "        \"\"\"\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.text(rect.get_x() + rect.get_width()/2., 1.05*height,\n",
    "                    '%.2f' % height,\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "    autolabel(rect)\n",
    "    plt.xlabel(para_name)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.savefig(file_name)\n",
    "    \n",
    "#This is for plot time against parameters in bar chart(decay)\n",
    "def plot_bar(filename, parameters, parameter_name, updatetimes, totaltimes):\n",
    "\n",
    "    \n",
    "    # update time\n",
    "    histogram(parameters, updatetimes, parameter_name, filename + '_update_time.png', 'time in ms', 'time for a weight update')\n",
    "    \n",
    "    # total time\n",
    "    histogram(parameters, totaltimes, parameter_name, filename + '_total_time.png', 'time in s', 'total time for training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data\n",
    "trainX, trainY = read_data('sat_train.txt')\n",
    "testX, testY = read_data('sat_test.txt')\n",
    "\n",
    "# Use min max value of traning data to do scaling\n",
    "X_min = np.min(trainX, axis=0)\n",
    "X_max = np.max(trainX, axis=0)\n",
    "\n",
    "trainX = scale(trainX)\n",
    "testX = scale(testX)\n",
    "    \n",
    "print(trainX.shape, trainY.shape)\n",
    "print(testX.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question 1\n",
    "\n",
    "decay = 1e-6\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "num_neurons = 10\n",
    "batch_size = 32\n",
    "\n",
    "train_cost, test_accuracy, update_time, total_time = train_network(trainX, trainY, testX, testY, decay, learning_rate, epochs, batch_size, num_neurons)\n",
    "plot1(filename='./graph_theano/1/question1', train_cost=train_cost, test_accuracy=test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question 2\n",
    "\n",
    "decay = 1e-6\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "num_neurons = 10\n",
    "batches = [4, 8, 16, 32, 64]\n",
    "\n",
    "updateTimes = []\n",
    "totalTimes = []\n",
    "\n",
    "for batch_size in batches:\n",
    "    print(\"Running batch size: \"+str(batch_size))\n",
    "    train_cost, test_accuracy, update_time, total_time = train_network(trainX, trainY, testX, testY, decay, learning_rate, epochs, batch_size, num_neurons)\n",
    "    updateTimes.append(update_time)\n",
    "    totalTimes.append(total_time/1000)\n",
    "    \n",
    "    print(\"Taken average \" + str(update_time) + \" ms to update weight once\")\n",
    "    print(\"Taken \" + str(total_time/1000) + \" s total time\")\n",
    "    plot1(filename='./graph_theano/2/batch_'+str(batch_size), train_cost=train_cost, test_accuracy=test_accuracy)\n",
    "\n",
    "plot2('./graph_theano/2/batch', batches, 'batch size', updateTimes, totalTimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question 3\n",
    "\n",
    "decay = 1e-6\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "nums_neurons = [5, 10, 15, 20, 25]\n",
    "batch_size = 4\n",
    "\n",
    "updateTimes = []\n",
    "totalTimes = []\n",
    "\n",
    "for num_neurons in nums_neurons:\n",
    "    print(\"Running num of neurons: \"+str(num_neurons))\n",
    "    train_cost, test_accuracy, update_time, total_time = train_network(trainX, trainY, testX, testY, decay, learning_rate, epochs, batch_size, num_neurons)\n",
    "    updateTimes.append(update_time)\n",
    "    totalTimes.append(total_time/1000)\n",
    "    \n",
    "    print(\"Taken average \" + str(update_time) + \" ms to update weight once\")\n",
    "    print(\"Taken \" + str(total_time/1000) + \" s total time\")\n",
    "    plot1(filename='./graph_theano/3/neurons_'+str(num_neurons), train_cost=train_cost, test_accuracy=test_accuracy)\n",
    "\n",
    "plot2('./graph_theano/3/neurons', nums_neurons, 'number of neurons', updateTimes, totalTimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4\n",
    "\n",
    "decays = [0, 1e-3, 1e-6, 1e-9, 1e-12]\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "num_neurons = 15\n",
    "batch_size = 4\n",
    "\n",
    "updateTimes = []\n",
    "totalTimes = []\n",
    "\n",
    "for decay in decays:\n",
    "    print(\"Running decay: \"+str(decay))\n",
    "    train_cost, test_accuracy, update_time, total_time = train_network(trainX, trainY, testX, testY, decay, learning_rate, epochs, batch_size, num_neurons)\n",
    "    updateTimes.append(update_time)\n",
    "    totalTimes.append(total_time/1000)\n",
    "    \n",
    "    print(\"Taken average \" + str(update_time) + \" ms to update weight once\")\n",
    "    print(\"Taken \" + str(total_time/1000) + \" s total time\")\n",
    "    plot1(filename='./graph_theano/4/decay_'+str(decay), train_cost=train_cost, test_accuracy=test_accuracy, epochs=epochs)\n",
    "\n",
    "plot_bar('./graph_theano/4/decay_', decays, 'decay', updateTimes, totalTimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5\n",
    "\n",
    "decay = 1e-6\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "num_neurons = 10\n",
    "batch_size = 32\n",
    "\n",
    "updateTimes = []\n",
    "totalTimes = []\n",
    "\n",
    "print(\"Running 4 layers...\")\n",
    "train_cost, test_accuracy, update_time, total_time = train_4layers(trainX, trainY, testX, testY, decays, learning_rate, epochs, batch_size, num_neurons)\n",
    "updateTimes.append(update_time)\n",
    "totalTimes.append(total_time/1000)\n",
    "\n",
    "print(\"Taken average \" + str(update_time) + \" ms to update weight once\")\n",
    "print(\"Taken \" + str(total_time/1000) + \" s total time\")\n",
    "plot1(filename='./graph_theano/5/4layers', train_cost=train_cost, test_accuracy=test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
